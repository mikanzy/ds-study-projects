# Определение токсичных комментариев

## Описание

Построена ML модель для классификации комментариев на позитивные (нормальные) и негативные (токсичные).

## Данные

Набор данных с разметкой о токсичности комментариев:

- Текст комментария;
- Целевой признак: 0 для нормальных комментариев и 1 для токсичных.


## Цель проекта

Построить модель классификации комментариев на позитивные (нормальные) и негативные (токсичные).

Значение метрики качества *F1* должно быть не меньше 0.75. 


## Задачи проекта

1. Загрузить и подготовить данные.

2. Обучить разные модели классификации на данных.

3. Проанализировать результаты и сделать выводы.


## Используемые библиотеки

*langid, lightgbm, matplotlib, numpy, pandas, regex, scikit-learn, seaborn, spacy, tqdm*


## Основные результаты

1. Установлено, что все тексты в корпусе на **английском языке**.

2. Проведена **обработка** текстов и их **подготовка** для обучения ML модели:
    - приведение символов к нижнему регистру,
    - очистка от URL, email, HTML-тегов, небуквенных и нелатинских символов, диакритических знаков,
    - лемматизация слов,
    - удаление стоп-слов,
    - удаление пустых текстов, появившихся в результате обработки,
    - векторизация текстов путём расчёта значений TF-IDF каждого отдельного слова в корпусе.
  
3. Обнаружен **дисбаланс классов**: доля токсичных комментариев в датасете составляет всего 10%. Этот факт учтён и при подготовке выборок для обучения и проверки качества ML модели, и при построении модели.

4. Построена и обучена **ML модель**, которая классифицирует комментарии на токсичные и нормальные. Значение метрики *F1* модели на тестовой выборке превышает 0.76, что удовлетворяет заданному требованию *F1* > 0.75.

5. Построенная ML модель смогла верно выявить **83%** токсичных комментариев. При этом среди комментариев, которые модель классифицировала как токсичные, таковыми на самом деле оказались лишь **70%**. 

6. Наиболее значимым для модели признаком, который повышает вероятность классификации комментария как токсичного, является наличие в тексте **обсценной и оскорбительной лексики**.


## Заключение

Построенная модель классификации довольно хорошо, хотя и не идеально, выявляет токсичные комментарии, но также нередко считает токсичными и нормальные комментарии — в этом случае требуется рассмотрение модератором. При этом модель смогла правильно уловить связь между наличием в тексте комментария обсценной и оскорбительной лексики и его токсичностью.
